{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA using autoencoder\n",
    "\n",
    "When analyzing large datasets, it is important to preprocess the data to prevent potential overfitting (curse of dimensionality). Dimension reduction is one such technique that identifies a small set of features to represent a large dataset. Features are chosen based on how well they capture underlying structure in the data based on certain criteria. For example, in principle component analysis (PCA), features are selected from principle components that best explain the variance in the data i.e., if a dataset varies wildly in a certain direction, the corresponding vector is selected as a feature.\n",
    "\n",
    "Another way to encode data is to use an autoencoder (AE). The autoencoder first encodes data into a latent space (often of a smaller dimension than the input data) using one or more layers, and decodes points in the latent space back to the original data. The goal is learn features that reduce the difference between the original and reconstructed data.\n",
    "\n",
    "Autoencoders are often compared to PCA. In fact, an autoencoder that is a single layer deep (1 for encoding, 1 for decoding) and uses linear activation is often thought to function like PCA in the roughest of sense. However, there are several differences between both methods.\n",
    "1. PCA, and covariance, is primarily a linear operation. It cannot learn non-linear features the same way autoencoders can using non-linear kernels. That said, kernel PCA is one way to extend linear PCA to non-linear data.\n",
    "1. PCA eigenvectors are orthorgonal by default. AE weights are not orthorgonal necessarily but instead overlap, sometimes significantly. ~~This non-orthorgonality could potentially contribute to the non-linearity since it scales the importance of certain vectors in a non-linear fashion.~~\n",
    "1. PCA transforms and reconstructs the data using the same transformation (eigenvector) matrix. The encoder and decoder layer on the other hand have different weights.\n",
    "\n",
    "I will show that it is possible to configure an autoencoder to produce the same results as PCA and not just approximate it!\n",
    "\n",
    "Note: Performing PCA using autoencoders makes little sense because the code is complicated and computationally intensive compared to PCA. However, if we can recreate PCA using an autoencoder, it means we can treat autoencoders as less of a 'black box' and more of a PCA analog which we can further improve on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(123)\n",
    "#from tensorflow import set_random_seed\n",
    "#set_random_seed(234)\n",
    "\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import decomposition\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Layer, InputSpec\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras import regularizers, activations, initializers, constraints, Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.constraints import UnitNorm, Constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "1. Generate data from cov matrix and mu\n",
    "2. Preprocess data. Check out [link](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function\n",
    "def correlation_from_covariance(covariance):\n",
    "    v = np.sqrt(np.diag(covariance))\n",
    "    outer_v = np.outer(v, v)\n",
    "    correlation = covariance / outer_v\n",
    "    correlation[covariance == 0] = 0\n",
    "    return correlation\n",
    "\n",
    "# Generate Data\n",
    "n_dim = 5 # 5 dimensional data\n",
    "cov = sklearn.datasets.make_spd_matrix(n_dim, random_state=1234) # Generate\n",
    "corr = correlation_from_covariance(cov)\n",
    "mu = np.random.normal(0, 0.1, n_dim) # Generate mean\n",
    "n = 1000 # Number of samples\n",
    "X = np.random.multivariate_normal(mu, cov, n)\n",
    "#X = X.astype('float32')\n",
    "\n",
    "# Preprocess data\n",
    "X_train, X_test = train_test_split(X, test_size=0.01, random_state=123)\n",
    "scaler = StandardScaler() #Translate data and scale them such that stddev is 1\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "We first perform a standard PCA. As a recap, PCA is simply the eigendecomposition the covariance matrix. To get a graphical intuition of what PCA does, we need to understand what the covariance matrix. Graphically, for 2D data, the covariance matrix describes the shape of the data on a plane. It is basically a transformation matrix that shapes data distributed in a circle (cov(x,y)=0, var(x)=1, var(y)=1) into a skewed ellipse.\n",
    "\n",
    "When we perform eigendecomposition, we are essentially breaking down the transformation into separate scaling and skewing/rotating operations. The eigenvector matrix unskews the data, and a diagonal eigenvalue matrix scales the data. Note that the eigenvalues are the variance of the data along the eigenvectors i.e. the lengths of the major and minor axis of the ellipse.\n",
    "\n",
    "We will perform PCA using\n",
    "1. Original COV\n",
    "2. Derived COV\n",
    "\n",
    "To check if the vectors are in the same direction, we perform a dot product of the unit vectors. If the value is close to 1 i.e the eigenvectors from both COV matrix have very similar directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9994963369640623, 0.9969036756495246, 0.9951763361207062, -0.997480966498134, 0.999576873741542]\n"
     ]
    }
   ],
   "source": [
    "# Original COV\n",
    "values, vectors = scipy.linalg.eig(corr) # Vector are columns\n",
    "idx = np.argsort(values*-1)\n",
    "values, vectors = values[idx], vectors[:,idx]\n",
    "ratio = values/values.sum() # Explained Variance Ratio\n",
    "\n",
    "# Derived COV\n",
    "pca_analysis = sklearn.decomposition.PCA()\n",
    "pca_analysis.fit(X_train_scaled)\n",
    "cov2 = pca_analysis.get_covariance()\n",
    "vectors2 = pca_analysis.components_ # Vector are rows\n",
    "values2 = pca_analysis.explained_variance_\n",
    "ratio2 = pca_analysis.explained_variance_ratio_\n",
    "cov2, corr\n",
    "# Compare eigenvectors and eigenvalues\n",
    "values, values2\n",
    "vectors.T, vectors2\n",
    "cross_prod = []\n",
    "for i in range(n_dim):\n",
    "    cross_prod.append(np.dot(vectors.T[i], vectors2[i])/(scipy.linalg.norm(vectors.T[i])*scipy.linalg.norm(vectors2[i])))\n",
    "\n",
    "print(cross_prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Autoencoder\n",
    "\n",
    "I'll first demonstrate how to create an autoencoder in tensorflow using the basic layers. Since I'll need to customize the training loop later, it is easier to create a tensorflow model using subclass instead of sequential or functional API.\n",
    "\n",
    "## Set up model and layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 100 #Number of runs\n",
    "batch_size = 16\n",
    "input_dim = X_train_scaled.shape[1] #Number of predictor variables,\n",
    "encoding_dim = 2\n",
    "learning_rate = 1e-2\n",
    "\n",
    "# Batch and shuffle data\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (X_train_scaled, X_train_scaled)).shuffle(1000).batch(batch_size)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test_scaled, X_test_scaled)).batch(batch_size)\n",
    "\n",
    "# Define model\n",
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Define the layers\n",
    "        self.d1 = Dense(encoding_dim, activation=\"linear\", input_shape=(input_dim,), use_bias=True, dtype='float32')\n",
    "        self.d2 = Dense(input_dim, activation=\"linear\", use_bias = True)\n",
    "\n",
    "    def call(self, x):\n",
    "        # Connecting the layers\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)\n",
    "\n",
    "# Create an instance of the model\n",
    "tf.keras.backend.clear_session()\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Select Loss function, Optimzer and Metric\n",
    "\n",
    "We define the **loss function** using mean squared error to evaluate the difference between the original and reconstructed data. The model **optimize** its weights using stochastic gradient descent, i.e. training the model using a gradients from a subset of input data. The **loss metric** is the mean of losses (MSE) for all data.\n",
    "\n",
    "Note: For sequential models, when choosing a loss metric in the `model.compile()` step, you may see 'accuracy' chosen in some examples. They don't make sense in a autoencoder since it is meant for categorial data, not continuous data.\n",
    "```python\n",
    "autoencoder.compile(metrics=['accuracy'],\n",
    "                    loss='mean_squared_error',\n",
    "                    optimizer='sgd')\n",
    "```\n",
    "* Tensorflow Issue #34451 - if you pass the string 'accuracy', we infer between binary_accuracy/categorical_accuracy functions\n",
    "* See more discussion [here](https://bit.ly/3dsyMwm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "assertion failed: [0] [Op:Assert] name: EagerVariableNameReuse",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3574fdc03590>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, dtype)\u001b[0m\n\u001b[1;32m    458\u001b[0m     \"\"\"\n\u001b[1;32m    459\u001b[0m     super(Mean, self).__init__(\n\u001b[0;32m--> 460\u001b[0;31m         reduction=metrics_utils.Reduction.WEIGHTED_MEAN, name=name, dtype=dtype)\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, reduction, name, dtype)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m       self.total = self.add_weight(\n\u001b[0;32m--> 296\u001b[0;31m           'total', initializer=init_ops.zeros_initializer)\n\u001b[0m\u001b[1;32m    297\u001b[0m       if reduction in [metrics_utils.Reduction.SUM_OVER_BATCH_SIZE,\n\u001b[1;32m    298\u001b[0m                        metrics_utils.Reduction.WEIGHTED_MEAN]:\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, aggregation, synchronization, initializer, dtype)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0;31m### End: For use by subclasses ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         caching_device=caching_device)\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m                         shape=None):\n\u001b[1;32m    196\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2594\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2596\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2597\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2598\u001b[0m     return variables.RefVariable(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1409\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1411\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m   def _init_from_args(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1555\u001b[0m               \u001b[0mshared_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshared_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m               \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1557\u001b[0;31m               graph_mode=self._in_graph_mode)\n\u001b[0m\u001b[1;32m   1558\u001b[0m         \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m         if (self._in_graph_mode and initial_value is not None and\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36meager_safe_variable_handle\u001b[0;34m(initial_value, shape, shared_name, name, graph_mode)\u001b[0m\n\u001b[1;32m    230\u001b[0m   \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m   return _variable_handle_from_shape_and_dtype(\n\u001b[0;32m--> 232\u001b[0;31m       shape, dtype, shared_name, name, graph_mode, initial_value)\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_variable_handle_from_shape_and_dtype\u001b[0;34m(shape, dtype, shared_name, name, graph_mode, initial_value)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;31m# support string tensors, we encode the assertion string in the Op name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     gen_logging_ops._assert(  # pylint: disable=protected-access\n\u001b[0;32m--> 164\u001b[0;31m         math_ops.logical_not(exists), [exists], name=\"EagerVariableNameReuse\")\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mhandle_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcpp_shape_inference_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCppShapeInferenceResult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHandleData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_logging_ops.py\u001b[0m in \u001b[0;36m_assert\u001b[0;34m(condition, data, summarize, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6605\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6606\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6607\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: assertion failed: [0] [Op:Assert] name: EagerVariableNameReuse"
     ]
    }
   ],
   "source": [
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up training steps and train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define training step\n",
    "@tf.function\n",
    "def train_step(input, output):\n",
    "      with tf.GradientTape() as tape:\n",
    "            predictions = model(input)\n",
    "            loss = loss_object(output, predictions)\n",
    "      # Backpropagation\n",
    "      gradients = tape.gradient(loss, model.trainable_variables)\n",
    "      optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "      # Log metric\n",
    "      train_loss.update_state(loss)\n",
    "\n",
    "@tf.function\n",
    "def test_step(input, output):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(input)\n",
    "    t_loss = loss_object(output, predictions)\n",
    "    # Log metric\n",
    "    test_loss(t_loss)\n",
    "    #test_accuracy(output, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "for epoch in range(nb_epoch):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    test_loss.reset_states()\n",
    "\n",
    "    for num, (input, output) in enumerate(train_ds):\n",
    "        train_step(input, output)\n",
    "\n",
    "    for input, output in test_ds:\n",
    "        test_step(input, output)\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Test Loss: {}'\n",
    "    if (epoch) % 10 ==0:\n",
    "        print(template.format(epoch,\n",
    "                        train_loss.result(),\n",
    "                        test_loss.result()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA-like Autoencoder\n",
    "The goal of creating a PCA-like autoencoder is to provide context to the underlying weights of the neural network. In a neural network, for linear activation, the first layer is essentially a projection of the data onto a space determined by the weights of the layer. The cartoon below illustrates how a neural network projects data onto a vector space determined by the weights. To avoid confusion, all subsequent mentions of weights refer to the weight vectors as shown in the figure.\n",
    "\n",
    "![](figures/DL-01.png)\n",
    "\n",
    "We will now introduce the following features to the autoencoder to replicate PCA:\n",
    "1. encoder and decoder share the same weights but tranposed.*\n",
    "    1. tied weight do not extend to biases\n",
    "1. linear activations.\n",
    "1. orthogonal weights.\n",
    "1. unit length weights\n",
    "1. encoder dimension increased and trained iteratively. Weights of previously trained dimensions are kept constant. This replicates the process of finding the eigen vector that best explains the data iteratively.\n",
    "1. loss function that minimizes variance of data in the latent space since we want the weights to function like eigenvectors.**\n",
    "\n",
    "\\*Note that the decoder is not strictly the inverse of the encoder. However, in the case of a PCA, the transpose of the unit eigenvector matrix is also the inverse, so if we transpose the weights of the encoder, we get a decoder that is effectively performing an inverse operation. For encoders with smaller dimension, the inverse operation is technically a pseudoinverse.\n",
    "\n",
    "\\*\\* Turns out, we don't need to create such a loss function explicitly since the autoencoder will try to minimize variance naturally for the MSE loss function. See discussion on AE at the end.\n",
    "\n",
    "As we will show later, **choosing either tied-weights, orthogonality weights or sequential training is sufficient for generating weights that are orthogonal**, though only sequential training ensures that the weights are the same as PCA's eigenvectors.\n",
    "\n",
    "## Adding orthogonality regularizer\n",
    "To ensure that the weights are orthogonal, we add a regularizer that penalizes weights that are not orthogonal. A quick way to define one is to recognize that if A is an orthonormal matrix, transpose(A) = inverse(A). If we multiply the orthonormal weight matrix by their transpose, we should get an identity matrix. Any deviation means the weights are not orthonormal, and we penalize it by adding the difference to the loss function.\n",
    "\n",
    "Note that we are not making this a constraint since we want the autoencoder to be able to choose slightly non-orthogonal weights if it results in a better fit, and an orthogonality regularizer is easier to implement.\n",
    "\n",
    "See [link](https://bit.ly/36PPG5W) for more details on the math.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Orthogonal(tf.keras.regularizers.Regularizer):\n",
    "    def __init__(self, encoding_dim, reg_weight = 1.0, axis = 0):\n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.reg_weight = reg_weight\n",
    "        self.axis = axis\n",
    "\n",
    "    def __call__(self, w):\n",
    "        if(self.axis==1):\n",
    "            w = K.transpose(w)\n",
    "        if(self.encoding_dim > 1):\n",
    "            m = K.dot(K.transpose(w), w) - K.eye(self.encoding_dim)\n",
    "            return self.reg_weight * K.sqrt(K.sum(K.square(K.abs(w))))\n",
    "        else:\n",
    "            m = K.sum(w ** 2) - 1.\n",
    "            return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential training\n",
    "\n",
    "A unique feature of the PCA is that each eigenvector accounts for some variance in the data in increasing order. However, in an autoencoder, the loss function is defined only by the accuracy of the reconstructed data. If we set the latent space to have the same dimension as the incoming data, it is possible for the autoencoder to find a set of orthogonal weights that transforms the data to a different latent space and back perfectly, **but the weights are more a reflection of the initial condition than useful information**.\n",
    "\n",
    "If the dimension of the latent space is smaller than that of the input, the weights need to compress the data more efficiently (i.e. account for as much variance in the data as possible), which constraints the weights slightly. However, there are still many ways to 'distribute' the data variance across different weight vectors, so the values are again dependent on the initialization. Put another way, if the encoding layer is 2D, there is a plane that best describes the data variance. As I show later, the autoencoder is capable of finding the plane, but may represent the plane with two different vectors compared to PCA.\n",
    "\n",
    "If we reduce the encoding layer to a dimension of 1, the one resulting weight vector has to account for as much variance as possible. Naturally, it has to be close to the first principle component (due to the tied weights regularization) and the variance of the projected data must be close to the first eigenvalue.\n",
    "\n",
    "Once we have found the first weight vector, we can fix it while training the second weight vector, subject to the same constraints as before. The autoencoder should in theory find a second weight vector that accounts for the second most variance of the data. We repeat this for all subsequent weights until the desired encoding dimension is achieved.\n",
    "\n",
    "Below, we introduce a new layer that generates seperate weight vectors instead of a kernel matrix. By declaring the weight vectors separately, we can train them individually while keeping previously trained vectors fixed. Additionally, all untrained weights should be set to zero so that they don't affect the training. When a weight vector is ready to be trained, change it from zero to the default kernel_initializer so that the model can learn more efficiently. `weight_ind` is defined as the index of the weight that is currently being trained. When calling the layer, the layer uses `weight_ind` to generate the appropriate kernel for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import math_ops, sparse_ops, gen_math_ops, nn\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "\n",
    "class DenseWeight(tf.keras.layers.Dense):\n",
    "    # source code for tf.keras.layers.Dense -> https://bit.ly/3ciTIEJ\n",
    "    def __init__(self, units, w_axis, **kwargs):\n",
    "        # w_axis (0 or 1) determines which axis the weight vectors are on.\n",
    "        # For encoder -> w_axis = 0, decoder -> w_axis = 1\n",
    "        super(DenseWeight, self).__init__(units, **kwargs)\n",
    "        self.w_axis = w_axis\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(DenseWeight,self).build(input_shape)\n",
    "        last_dim = tensor_shape.dimension_value(input_shape[-1])\n",
    "        self.kernelshape = [last_dim, self.units]\n",
    "        self.weightshape = [1,1]\n",
    "        self.weightshape[self.w_axis] = self.kernelshape[self.w_axis]\n",
    "        self.kernelall = []\n",
    "        # Setting separate weight vectors.\n",
    "        for i in range(self.kernelshape[int(not self.w_axis)]):\n",
    "            custominit = self.kernel_initializer\n",
    "            self.kernelall.append(self.add_weight(\n",
    "            name='w{:d}'.format(i), shape=self.weightshape,\n",
    "            initializer=custominit, regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint, dtype=self.dtype,\n",
    "            trainable=True))\n",
    "\n",
    "    def call(self, inputs, weight_ind=None):\n",
    "        # Set default\n",
    "        if weight_ind is None:\n",
    "            weight_ind = len(self.kernelall)-1\n",
    "        # Create kernel where the weights above weight_ind are zero so that they don't affect the training.\n",
    "        self.kerneltrain = [w if w_ind <= weight_ind else tf.zeros(w.shape) for w_ind, w in enumerate(self.kernelall)]\n",
    "        self.kernel = tf.concat(self.kerneltrain,int(not self.w_axis))\n",
    "        # Copied from source\n",
    "        return super(DenseWeight,self).call(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tying weights of encoder and decoder\n",
    "`DenseTranspose` creates a decoder layer that shares the same weight as the input encoder layer. More details are\n",
    "available in the [Link](https://bit.ly/2XTiKoT).\n",
    "\n",
    "Note that `shape=[self.dense.input_shape[-1]]` only work with a sequential or functional API model. In a subclass model, the layer can't infer the input_shape from the upstream layer until the model is called, but it needs that information before that.\n",
    "\n",
    "`TiedModel` creates an autoencoder the connects `DenseWeight` and `DenseTranspose`. When calling the model, add `d1_weight_ind` so that layer DenseWeight generates the correct kernel for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class DenseTranspose(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, dense, activation=None, use_bias=True,\n",
    "                bias_initializer='zeros', **kwargs):\n",
    "        self.units = units # number of nodes in layer\n",
    "        self.dense = dense\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.bias_initializer = bias_initializer\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.use_bias:\n",
    "            self.biases = self.add_weight(name = \"bias\",\n",
    "                        initializer = self.bias_initializer,\n",
    "                        shape = [self.units,])\n",
    "        #super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        #z = tf.matmul(inputs, self.dense.weights[0], transpose_b=True)\n",
    "        z = tf.matmul(inputs, self.dense.kernel, transpose_b=True)\n",
    "        if self.use_bias:\n",
    "            return self.activation(z + self.biases)\n",
    "        else:\n",
    "            return self.activation(z)\n",
    "\n",
    "class TiedModel(Model):\n",
    "    def __init__(self):\n",
    "        super(TiedModel, self).__init__()\n",
    "        # Define the layers\n",
    "        self.d1 = DenseWeight(encoding_dim, w_axis=0,activation=\"linear\",\n",
    "        input_shape=(input_dim,), use_bias=False, dtype='float32',\n",
    "        kernel_regularizer=Orthogonal(encoding_dim, reg_weight=1., axis=0),\n",
    "        kernel_constraint=tf.keras.constraints.UnitNorm(axis=0))\n",
    "        #self.d2 = Dense(input_dim, activation=\"linear\", use_bias = True)\n",
    "        self.d2 = DenseTranspose(input_dim, self.d1, use_bias=False, activation=\"linear\")\n",
    "        #self.d2 = MyDenseLayer(input_dim)\n",
    "\n",
    "    def call(self, x, d1_weight_ind=None):\n",
    "        # Connecting the layers\n",
    "        x = self.d1(x, d1_weight_ind)\n",
    "        x = self.d2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing sequential training\n",
    "\n",
    "To specify which vector to train, we define `var_list`, which is used by the optimizer to determine which variable to train. Note that `var_list` should not be defined in `train_step` since it uses python features that are not compatible with `@tf.function`. See [link](https://bit.ly/3dxUT4U)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the model\n",
    "tf.keras.backend.clear_session()\n",
    "model = TiedModel()\n",
    "\n",
    "# Select Loss function, Optimizer and Metric\n",
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "\n",
    "# Define training step\n",
    "@tf.function\n",
    "def train_step(input, output, d1_weight_ind, var_list):\n",
    "      with tf.GradientTape() as tape:\n",
    "        predictions = model(input, d1_weight_ind)\n",
    "        loss = loss_object(output, predictions)\n",
    "      # Backpropagation\n",
    "      gradients = tape.gradient(loss, var_list)\n",
    "      optimizer.apply_gradients(zip(gradients, var_list))\n",
    "      # Log metric\n",
    "      train_loss.update_state(loss)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_step(input, output):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(input)\n",
    "    t_loss = loss_object(output, predictions)\n",
    "    # Log metric\n",
    "    test_loss(t_loss)\n",
    "    #test_accuracy(output, predictions)\n",
    "\n",
    "\n",
    "nb_epoch = 31 #number of epochs per weight vector\n",
    "d1_weight_ind = 0\n",
    "while d1_weight_ind <= encoding_dim-1:\n",
    "    for epoch in range(nb_epoch):\n",
    "        # Reset the metrics at the start of the next epoch\n",
    "        train_loss.reset_states()\n",
    "        test_loss.reset_states()\n",
    "\n",
    "        for num, (input, output) in enumerate(train_ds):\n",
    "            var_list = []\n",
    "            untrainable_weights = [i for ind, i in enumerate(model.d1.weights) if ind != d1_weight_ind]\n",
    "            for v in model.trainable_variables:\n",
    "                append = True\n",
    "                for w in untrainable_weights:\n",
    "                    if v is w:\n",
    "                        append = False\n",
    "                        break\n",
    "                if append:\n",
    "                    var_list.append(v)\n",
    "            train_step(input, output, d1_weight_ind, var_list)\n",
    "\n",
    "        for input, output in test_ds:\n",
    "            test_step(input, output)\n",
    "\n",
    "        template = 'Epoch {}, Loss: {}, Test Loss: {}'\n",
    "        if epoch % 10 == 0:\n",
    "            print(template.format(epoch,\n",
    "                            train_loss.result(),\n",
    "                            test_loss.result()))\n",
    "\n",
    "    d1_weight_ind+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing weights\n",
    "Let's compare weights/eigenvectors and projected data variance/eigenvalues.\n",
    "\n",
    "### Orthorgonality\n",
    "The dot product of the eigenvector matrix `enc_weights` and its transpose is approximately the identity matrix i.e. the weights are orthogonal.\n",
    "\n",
    "### Eigenvalues and Eigenvectors\n",
    "The 'eigenvalue' of the a weight vector can be obtained by projecting the data onto the vector and calculating the resulting variance. We shall call the variance the **projected variance**.\n",
    "\n",
    "The eigenvalues and eigenvectors for very close to the weights and projected variance.\n",
    "\n",
    "### Eigenvector directions\n",
    "We can further test the direction of the eigenvector vs weights by taking the dot product of their unit vectors. The closer they are to 1, the smaller the angle between the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_weights = tf.concat(model.d1.weights,axis=1).numpy()\n",
    "print('Check Orthogonality\\n{}\\n'.format(np.dot(enc_weights.T,enc_weights))) # Check for weight orthogonality\n",
    "enc_values = np.dot(X_train_scaled, enc_weights).var(axis=0) # Get variance / eigenvalue\n",
    "idx = np.argsort(enc_values*-1) # Sort the weights by data variance\n",
    "values3, vectors3 = enc_values[idx], enc_weights[:,idx]\n",
    "\n",
    "# Compare eigenvectors and eigenvalues\n",
    "print('Original EigVal\\n{}\\nDerived EigVal\\n{}\\nAutoencoder DataVar\\n{}\\n'.format(values, values2, values3))\n",
    "print('Original PC\\n{}\\nDerived PC\\n{}\\nAutoencoder Weights\\n{}\\n'.format(vectors.T, vectors2, vectors3.T))\n",
    "\n",
    "# Compare direction of eigenvectors and weights\n",
    "def dp(a,b):\n",
    "    #pseudo\n",
    "    return np.dot(a, b)/(scipy.linalg.norm(a)*scipy.linalg.norm(b))\n",
    "\n",
    "dot_prod = []\n",
    "for i in range(vectors3.T.shape[0]):\n",
    "    dot_prod.append(dp(vectors2[i], vectors3.T[i]))\n",
    "\n",
    "print('Dot product of eigenvectors vs weights')\n",
    "print(dot_prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing loss between original autoencoder and PCA-like autoencoder\n",
    "\n",
    "Comparing the loss, it looks like the autoencoder performs similarly regardless of the PCA-inspired modifications. It suggests that the linear autoencoder is capable of finding the same latent space that best represents the data (i.e. the latent space that best reduces MSE) regardless of modifications. **The reason the weights are different is because the autoencoder choose to represent the same latent space using different weight vectors depending on the initialization.** By applying sequential training, the autoencoder selects meaningful vectors that are sorted by their power to reduce data variance. In fact, in `PCA_seqtrainonly.py`, sequential training alone of both encoder and decoder (i.e. training the first weight vector of encoder and decoder together followed by the second weight vector and so on) is sufficient for generating orthogonal weights, making the other modifications redundant!\n",
    "\n",
    "Another interesting feature is the redundancy of tied-weights and orthogonality regularization. Let's suppose for now that the unconstrained autoencoder returns orthogonal weights. If data dimension and encoding dimension are equal, the decoder simply takes the transpose (inverse) of the encoder weights to reconstruct the data perfectly. If encoding dimension is smaller, the transpose won't give us a perfect reconstruction, but one that minimizes MSE. The transpose of a non-square orthogonal matrix is also known as the pseudoinverse matrix. Conversely, if we tie the weights between encoder and decoder (via a transpose), the learned weights must be orthogonal since the loss is the same either way. Note that the redundancy only holds if the loss criteria is MSE. See `PCA_tiedonly.py` for more details.\n",
    "\n",
    "TL;DR Either one of these modifications, sequential training; tied-weights or orthogonality regularization, guarantees orthogonal weights when coupled with MSE loss. Only sequential training sorts the weights by 'eigenvalues' and matches the eigenvectors from PCA.\n",
    "\n",
    "### Pseudoinverse matrix and autoencoder\n",
    "Now let's suppose that the unconstrained autoencoder returns weights that are non-orthogonal. Since the autoencoder is representing the same optimal latent space with non-orthogonal weights, simply taking a transpose to decode the data will not work. Nevertheless, the decoder is able to find a set of weights that minimizes MSE. Turns out, the decoder weights match the **pseudoinverse matrix** calculated using SVD or `np.linalg.pinv`. The encoder projects data onto a latent space and transforms its coordinates, the decoder merely transforms the coordinates back but without 'unprojecting' the data, as shown in the cartoon below. An interesting property of pseudoinverse matrices is that multiplying a matrix by its pseudoinverse will yield an identity matrix (in the smaller dimension). See [link](https://bit.ly/2XNcYVC) for more details on pseudoinverse matrices.\n",
    "\n",
    "![](figures/DL-02.png)\n",
    "\n",
    "## Conclusion\n",
    "A linear autoencoder with MSE loss performs similarly to PCA. Given enough epochs, it'll find the same latent space as as the one found by PCA to minimize variance. The modifications proposed here do affect the latent space. Instead, they help the autoencoder look for vector representation of the latent space that are both interpretable and meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Futher insights and future work\n",
    "1. Given that MSE loss function is key to finding the right latent space that minimizes variance, **using a different the loss function** will produce a latent space that optimizes other characteristic in the data.\n",
    "1. Biases matter if the data was not preprocessed. However, it complicates PCA <-> autoencoder analogy since biases don't have a simple inverse operation the same way weight matrices can be transposed. \n",
    "1. Non-linearity can be achieved by using non-linear activation, or by changing the number of layers?\n",
    "1. The first layer projects the data onto an optimal latent space and determines the bulk of the compression. i.e. if the first encoding dimension is small, the subsequent layers won't be able to recover information that's lost.\n",
    "1. The second/subsequent layers would look for trends in the latent space and alter it, such as prioritizing locality in the latent space for data sharing the same label. (See VAE)\n",
    "1. Fourier compression essentially transforms signals to frequency components and removes high frequency ones. Analagously, autoencoder transforms data to a different latent space and projects them onto important vectors in a single step.\n",
    "1. Comparing VAE and LDA, PCoA and tSNE\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
